#è¿™æ˜¯Gr00tä¸“ç”¨çš„serveræ–‡ä»¶
'''ç«¯å£é€»è¾‘ï¼š
eval_main.py
  |
  | POST http://127.0.0.1:9000/act
  v
server_Gr00t.py   (uvicorn ç›‘å¬ 9000)
  |
  | Gr00tHTTPClient.post â†’ http://127.0.0.1:8000/act
  v
Gr00t åŽŸç”Ÿæ¨¡åž‹æœåŠ¡ (ç›‘å¬ 8000)
'''
'''å¯åŠ¨æ–¹å¼ï¼š
uvicorn scripts.eval.server_Gr00t:app \
    --host 127.0.0.1 \
    --port 9000
'''

from fastapi import FastAPI
import numpy as np
from PIL import Image
from internnav.evaluator.gr00t_http_client import Gr00tHTTPClient   # ðŸ”´ Gr00t æ¨¡åž‹è°ƒç”¨
import torch
    
app = FastAPI()

# ===== ðŸ”´ Gr00t æ¨¡åž‹åŠ è½½ï¼ˆæ¨¡åž‹ç‰¹æœ‰ï¼‰=====
#æ³¨ï¼šè¿™é‡Œæ­£å¸¸å¯åŠ¨æ¨¡åž‹å³å¯ï¼Œå¦‚æžœåœ¨æœ¬åœ°æœ‰ç›´æŽ¥åŠ è½½å³å¯ï¼Œè¿™é‡Œæ˜¯gr00téœ€è¦ä¸€ä¸ªæ–°ç«¯å£è¿è¡ŒæŽ¨ç†æœåŠ¡
#æ³¨æ„eval_main.pyä¸­çš„urlè¦æŒ‡å‘æœ¬æœåŠ¡å¯åŠ¨æ—¶çš„ç«¯å£("http://127.0.0.1:9000/act")ï¼Œè€Œä¸æ˜¯è¿™ä¸ªç«¯å£ï¼Œè¿™ä¸ªç«¯å£åªæ˜¯ç”¨äºŽåŽŸæœ¬çš„gr00tæŽ¨ç†æœåŠ¡çš„ï¼Œæ›´æ¢æ¨¡åž‹ä¸éœ€è¦è¿™ä¸ªç«¯å£
gr00t_client = Gr00tHTTPClient(
    url="http://127.0.0.1:8000/act"  # çœŸæ­£çš„ Gr00t æœåŠ¡
)

# ===== æž„å»ºGr00t æ¨¡åž‹è¾“å…¥ =====
def build_gr00t_obs(
    obs: dict,
):
    """
    obs: build_traj_request() ç”Ÿæˆçš„ dict
    """
    rgb = obs["rgb"]
    gps = obs["gps"]
    yaw = obs["yaw"]
    camera_height = obs["camera_height"]
    instruction = obs["instruction"]

    image = Image.fromarray(rgb).convert("RGB")
    rgb_256 = np.array(image.resize((256, 256)))

    drone_state = np.array(
        [gps[0], gps[1], camera_height, yaw],
        dtype=np.float32
    ).reshape(1, 4)

    return {
        "video.ego_view": rgb_256.reshape(1, 256, 256, 3),
        "state.drone": drone_state,
        "annotation.human.action.task_description": [instruction],
    }

#æŽ¥å—è¯·æ±‚å¹¶å®Œæˆå®žé™…æŽ¨ç†çš„ä¸»è¦é€»è¾‘
@app.post("/act")
def act(req: dict):
    """
    req = {
        "observation": build_traj_request(...) çš„è¾“å‡º
    }
    """
    obs = req["observation"]

    # ===== ðŸ”´ Gr00t ç§æœ‰ preprocessing =====
    #æž„é€ è¾“å…¥
    gr00t_obs = build_gr00t_obs(obs)

    # ðŸ”´ è°ƒç”¨â€œçœŸæ­£çš„ Gr00t æœåŠ¡â€
    gr00t_output = gr00t_client.get_action(gr00t_obs)
    if isinstance(gr00t_output, dict) and "action.delta_pose" in gr00t_output:
        delta_poses = gr00t_output["action.delta_pose"]
    else:
        delta_poses = gr00t_output
    #åˆ°è¿™é‡Œä¸ºæ­¢æ‹¿åˆ°äº†gr00tæ¨¡åž‹çš„è¾“å‡º

    # ===== ðŸ”´ Gr00t ç§æœ‰ postprocess =====
    #å°†è¾“å‡ºè½¬æ¢æˆæ­£ç¡®çš„æ ¼å¼ï¼Œå¦‚åˆ é™¤ä¸€åˆ—(1,T,4)å˜ä¸º(1,T,3)æˆ–è€…ç›¸å…³æ•°æ®æ¯”å¦‚è§’åº¦çš„å½’ä¸€åŒ–
    dp_actions = gr00t_output_to_dp_actions(delta_poses)
    # print("dp_actions:",dp_actions)

    #å°†è½¬æ¢ä¸ºæ­£ç¡®æ ¼å¼çš„è¾“å‡ºè½¬æ¢ä¸ºç¦»æ•£åŠ¨ä½œactionå¦‚[1ï¼Œ2ï¼Œ0]
    actions = traj_to_actions_Gr00t(dp_actions)

    # è¿”å›ž Habitat action id list
    return {
        "actions": actions
    }

#ä¸‹é¢æ˜¯ç”¨åˆ°çš„å‡½æ•°ï¼ŒæŒ‰æƒ…å†µæ›´æ”¹ä½¿ç”¨æˆ–æ–°å¢žå³å¯
def gr00t_output_to_dp_actions(gr00t_out):
        """
        æŠŠ Gr00t è¾“å‡ºè½¬æ¢ä¸º traj_to_actions_Gr00t éœ€è¦çš„æ ¼å¼ã€‚

        æ”¯æŒä»¥ä¸‹ gr00t_out å½¢å¼ï¼š
        - numpy array shape (T, 4)  # å•åºåˆ—
        - numpy array shape (1, T, 4)  # batch=1
        - torch tensor åŒä¸Š

        Gr00t è¾“å‡ºåˆ— assumed: [dx, dy, dz, dyaw_degrees]
        è¿”å›ž: torch.Tensor shape (1, T, 3) dtype=float32, last dim = [dx, dy, dyaw_rad*12]
        """
        # è½¬ numpy / torch å…¼å®¹
        if isinstance(gr00t_out, torch.Tensor):
            arr = gr00t_out.detach().cpu().numpy()
        else:
            arr = np.asarray(gr00t_out)

        # æ”¯æŒ (T,4) æˆ– (1,T,4) æˆ– (B,T,4)
        if arr.ndim == 2 and arr.shape[1] == 4:
            arr = arr[None, :, :]  # -> (1, T, 4)
        elif arr.ndim == 3 and arr.shape[2] == 4:
            pass
        else:
            raise ValueError(f"Unsupported gr00t_out shape: {arr.shape}, expected (T,4) or (1,T,4) or (B,T,4)")

        # å– (dx, dy, dyaw)
        # åˆ—ç´¢å¼•å‡è®¾ï¼š 0=dx, 1=dy, 2=dz (unused), 3=dyaw (å•ä½ï¼šåº¦)
        dx = arr[:, :, 0].astype(np.float32)
        dy = arr[:, :, 1].astype(np.float32)
        dyaw_deg = arr[:, :, 3].astype(np.float32)

        # deg -> rad
        dyaw_rad = np.deg2rad(dyaw_deg)

        # æ ¹æ®ä¹‹å‰è®¨è®ºï¼ŒæŠŠ yaw æ”¾å¤§ï¼ˆä¿æŒå’Œ traj_to_actions_Gr00t é‡Œç›¸åŒçš„æ”¾å¤§é€»è¾‘ï¼‰
        dyaw_rad = dyaw_rad * 1.0  # base conversion
        # æ³¨æ„ï¼štraj_to_actions_Gr00t ä¼šå†åš *=12 çš„å¤„ç†ï¼ˆå¦‚æžœä½ åœ¨å‡½æ•°é‡Œä¿ç•™é‚£ä¸€è¡Œï¼‰
        # æ­¤å¤„ä¸å†é‡å¤ä¹˜ 12ï¼Œé™¤éžä½ åœ¨ traj_to_actions_Gr00t ä¸­æ²¡æœ‰åŠ é‚£ä¸€è¡Œã€‚

        dp = np.stack([dx, dy, dyaw_rad], axis=-1)  # (B, T, 3)

        return torch.from_numpy(dp).float()  # è¿”å›ž torch Tensor (B, T, 3)

def traj_to_actions_Gr00t(dp_actions,use_discrate_action=True):
    def reconstruct_xy_from_delta(delta_xyt):
        """
        Input:
            delta_xyt: [B, T, 3], dx, dy are position increments in global coordinates, dÎ¸ is heading difference (not used for position)
            start_xy: [B, 2] starting point
        Output:
            xy: [B, T+1, 2] reconstructed global trajectory
        """
        start_xy = np.zeros((len(delta_xyt), 2))
        delta_xy = delta_xyt[:, :, :2]  # Take dx, dy parts
        cumsum_xy = np.cumsum(delta_xy, axis=1)  # [B, T, 2]

        B = delta_xyt.shape[0]
        T = delta_xyt.shape[1]
        xy = np.zeros((B, T + 1, 2))
        xy[:, 0] = start_xy
        xy[:, 1:] = start_xy[:, None, :] + cumsum_xy

        return xy

    def trajectory_to_discrete_actions_close_to_goal(trajectory, step_size=0.25, turn_angle_deg=15, lookahead=4):
        actions = []
        yaw = 0.0
        pos = trajectory[0]
        turn_angle_rad = np.deg2rad(turn_angle_deg)
        traj = trajectory
        goal = trajectory[-1]

        def normalize_angle(angle):
            return (angle + np.pi) % (2 * np.pi) - np.pi

        while np.linalg.norm(pos - goal) > 0.2:
            # Find the nearest trajectory point index to current position
            dists = np.linalg.norm(traj - pos, axis=1)
            nearest_idx = np.argmin(dists)
            # Look ahead a bit (not exceeding trajectory end)
            target_idx = min(nearest_idx + lookahead, len(traj) - 1)
            target = traj[target_idx]
            # Target direction
            target_dir = target - pos
            if np.linalg.norm(target_dir) < 1e-6:
                break
            target_yaw = np.arctan2(target_dir[1], target_dir[0])
            # Difference between current yaw and target yaw
            delta_yaw = normalize_angle(target_yaw - yaw)
            n_turns = int(round(delta_yaw / turn_angle_rad))
            if n_turns > 0:
                actions += [2] * n_turns
            elif n_turns < 0:
                actions += [3] * (-n_turns)
            yaw = normalize_angle(yaw + n_turns * turn_angle_rad)

            # Move forward one step
            next_pos = pos + step_size * np.array([np.cos(yaw), np.sin(yaw)])

            # If moving forward one step makes us farther from goal, stop
            if np.linalg.norm(next_pos - goal) > np.linalg.norm(pos - goal):
                break

            actions.append(1)
            pos = next_pos

        return actions

    # unnormalize
    dp_actions[:, :, :2] /= 4.0
    all_trajectory = reconstruct_xy_from_delta(dp_actions.float().cpu().numpy())
    trajectory = np.mean(all_trajectory, axis=0)
    if use_discrate_action:
        actions = trajectory_to_discrete_actions_close_to_goal(trajectory)
        return actions
    else:
        return trajectory